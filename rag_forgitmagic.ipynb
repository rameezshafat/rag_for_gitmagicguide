{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0e9f08-5b07-4b36-96a6-49eb2daa4a4b",
   "metadata": {},
   "source": [
    "## document preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81f34b1-3fc5-40ba-afab-6b637ea80953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./git_magic.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "pdf_path = \"./git_magic.pdf\"\n",
    "\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"File {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c818237-02f2-4c74-8b00-96ad602f0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.11-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading PyMuPDF-1.24.11-cp38-abi3-macosx_11_0_arm64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.11\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51698c0a-b11d-49be-9ab2-afaf7c76ff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831c6e584e124bf199bf62d9ca269864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 1419,\n",
       "  'page_word_count': 228,\n",
       "  'page_sentence_count_raw': 21,\n",
       "  'page_token_count': 354.75,\n",
       "  'text': 'Git Magic Ben Lynn August 2007 Preface Git is a version control Swiss army knife. A reliable versatile multipurpose revision control tool whose extraordinary flexibility makes it tricky to learn, let alone master. As Arthur C. Clarke observed, any suﬀiciently advanced technology is indistin- guishable from magic. This is a great way to approach Git: newbies can ignore its inner workings and view Git as a gizmo that can amaze friends and infuriate enemies with its wondrous abilities. Rather than go into details, we provide rough instructions for particular effects. After repeated use, gradually you will understand how each trick works, and how to tailor the recipes for your needs. • Simplified Chinese: by JunJie, Meng and JiangWei. Converted to Tradi- tional Chinese via cconv -f UTF8-CN -t UTF8-TW. • French: by Alexandre Garel, Paul Gaborit, and Nicolas Deram. • German: by Benjamin Bellee and Armin Stebich; also hosted on Armin’s website. • Italian: by Mattia Rigotti. • Korean: by Jung-Ho (John) Han; also hosted on John’s website. • Polish: by Damian Michna. • Brazilian Portuguese: by José Inácio Serafini and Leonardo Siqueira Ro- drigues. • Russian: by Tikhon Tarnavsky, Mikhail Dymskov, and others. • Spanish: by Rodrigo Toledo and Ariset Llerena Tapia. • Ukrainian: by Volodymyr Bodenchuk. • Vietnamese: by Trần Ngọc Quân; also hosted on his website. • Single webpage: barebones HTML, with no CSS. 1'},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 1795,\n",
       "  'page_word_count': 264,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 448.75,\n",
       "  'text': '• PDF file: printer-friendly. • EPUB file: E-reader-friendly. • Debian package, Ubuntu package: get a fast and local copy of this site. Handy when this server is offline. • Physical book [Amazon.com]: 64 pages, 15.24cm x 22.86cm, black and white. Handy when there is no electricity. Thanks! I’m humbled that so many people have worked on translations of these pages. I greatly appreciate having a wider audience because of the efforts of those named above. Dustin Sallings, Alberto Bertogli, James Cameron, Douglas Livingstone, Michael Budde, Richard Albury, Tarmigan, Derek Mahar, Frode Aannevik, Keith Rarick, Andy Somerville, Ralf Recker, Øyvind A. Holm, Miklos Vajna, Sébastien Hinderer, Thomas Miedema, Joe Malin, Tyler Breisacher, Sonia Hamilton, Julian Haagsma, Romain Lespinasse, Sergey Litvinov, Oliver Fer- rigni, David Toca, \\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff, Joël Thieffry, and Baiju Muthukadan contributed corrections and improvements. François Marier maintains the Debian package originally created by Daniel Bau- mann. My gratitude goes to many others for your support and praise. I’m tempted to quote you here, but it might raise expectations to ridiculous heights. If I’ve left you out by mistake, please tell me or just send me a patch! License This guide is released under the GNU General Public License, version 3 or any later version published by the Free Software Foundation. Naturally, the source is kept in a Git repository, and can be obtained by typing: $ git clone git://repo.or.cz/gitmagic.git # Creates \"gitmagic\" directory. or from one of the mirrors: $ git clone git://github.com/blynn/gitmagic.git $ git clone git://git.assembla.com/gitmagic.git $ git clone git@bitbucket.org:blynn/gitmagic.git GitHub, Assembla, and Bitbucket support private repositories, the latter two for free. 2'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "def text_formater(text: str) -> str: \n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text \n",
    "\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formater(text=text)\n",
    "        pages_and_texts.append({\n",
    "            \"page_number\" : page_number,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\" : len(text.split(\" \")),\n",
    "            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text)/4,\n",
    "            \"text\": text})\n",
    "    return pages_and_texts\n",
    "pages_and_texts = open_and_read_pdf(pdf_path = pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c29f4ac2-2e07-490a-8f36-8bbe6d6fdbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 10,\n",
       "  'page_char_count': 1776,\n",
       "  'page_word_count': 293,\n",
       "  'page_sentence_count_raw': 12,\n",
       "  'page_token_count': 444.0,\n",
       "  'text': '$ git push central.server/path/to/proj.git HEAD To check out the source, a developer types: $ git clone central.server/path/to/proj.git After making changes, the developer saves changes locally: $ git commit -a To update to the latest version: $ git pull Any merge conflicts should be resolved then committed: $ git commit -a To check in local changes into the central repository: $ git push If the main server has new changes due to activity by other developers, the push fails, and the developer should pull the latest version, resolve any merge conflicts, then try again. Developers must have SSH access for the above pull and push commands. How- ever, anyone can see the source by typing: $ git clone git://central.server/path/to/proj.git The native git protocol is like HTTP: there is no authentication, so anyone can retrieve the project. Accordingly, by default, pushing is forbidden via the git protocol. Secret Source For a closed-source project, omit the touch command, and ensure you never create a file named git-daemon-export-ok. The repository can no longer be retrieved via the git protocol; only those with SSH access can see it. If all your repos are closed, running the git daemon is unnecessary because all communi- cation occurs via SSH. Bare repositories A bare repository is so named because it has no working directory; it only contains files that are normally hidden away in the .git subdirectory. In other words, it maintains the history of a project, and never holds a snapshot of any given version. A bare repository plays a role similar to that of the main server in a centralized version control system: the home of your project. Developers clone your project from it, and push the latest oﬀicial changes to it. Typically it resides on a server 11'},\n",
       " {'page_number': 3,\n",
       "  'page_char_count': 2681,\n",
       "  'page_word_count': 463,\n",
       "  'page_sentence_count_raw': 26,\n",
       "  'page_token_count': 670.25,\n",
       "  'text': 'Distributed Control Now imagine a very diﬀicult computer game. So diﬀicult to finish that many experienced gamers all over the world decide to team up and share their saved games to try to beat it. Speedruns are real-life examples: players specializing in different levels of the same game collaborate to produce amazing results. How would you set up a system so they can get at each other’s saves easily? And upload new ones? In the old days, every project used centralized version control. A server some- where held all the saved games. Nobody else did. Every player kept at most a few saved games on their machine. When a player wanted to make progress, they’d download the latest save from the main server, play a while, save and upload back to the server for everyone else to use. What if a player wanted to get an older saved game for some reason? Maybe the current saved game is in an unwinnable state because somebody forgot to pick up an object back in level three, and they want to find the latest saved game where the game can still be completed. Or maybe they want to compare two older saved games to see how much work a particular player did. There could be many reasons to want to see an older revision, but the outcome is the same. They have to ask the central server for that old saved game. The more saved games they want, the more they need to communicate. The new generation of version control systems, of which Git is a member, are known as distributed systems, and can be thought of as a generalization of centralized systems. When players download from the main server they get every saved game, not just the latest one. It’s as if they’re mirroring the central server. This initial cloning operation can be expensive, especially if there’s a long history, but it pays off in the long run. One immediate benefit is that when an old save is desired for any reason, communication with the central server is unnecessary. A Silly Superstition A popular misconception is that distributed systems are ill-suited for projects requiring an oﬀicial central repository. Nothing could be further from the truth. Photographing someone does not cause their soul to be stolen. Similarly, cloning the master repository does not diminish its importance. A good first approximation is that anything a centralized version control system can do, a well-designed distributed system can do better. Network resources are simply costlier than local resources. While we shall later see there are drawbacks to a distributed approach, one is less likely to make erroneous comparisons with this rule of thumb. A small project may only need a fraction of the features offered by such a 4'},\n",
       " {'page_number': 30,\n",
       "  'page_char_count': 1828,\n",
       "  'page_word_count': 323,\n",
       "  'page_sentence_count_raw': 18,\n",
       "  'page_token_count': 457.0,\n",
       "  'text': '$ git archive --format=tar --prefix=proj-1.2.3/ HEAD Commit What Changed Telling Git when you’ve added, deleted and renamed files is troublesome for certain projects. Instead, you can type: $ git add . $ git add -u Git will look at the files in the current directory and work out the details by itself. Instead of the second add command, run git commit -a if you also intend to commit at this time. See git help ignore for how to specify files that should be ignored. You can perform the above in a single pass with: $ git ls-files -d -m -o -z | xargs -0 git update-index --add --remove The -z and -0 options prevent ill side-effects from filenames containing strange characters. As this command adds ignored files, you may want to use the -x or -X option. My Commit Is Too Big! Have you neglected to commit for too long? Been coding furiously and forgotten about source control until now? Made a series of unrelated changes, because that’s your style? No worries. Run: $ git add -p For each edit you made, Git will show you the hunk of code that was changed, and ask if it should be part of the next commit. Answer with ”y” or ”n”. You have other options, such as postponing the decision; type ”?” to learn more. Once you’re satisfied, type $ git commit to commit precisely the changes you selected (the staged changes). Make sure you omit the -a option, otherwise Git will commit all the edits. What if you’ve edited many files in many places? Reviewing each change one by one becomes frustratingly mind-numbing. In this case, use git add -i, whose in- terface is less straightforward, but more flexible. With a few keystrokes, you can stage or unstage several files at a time, or review and select changes in particular files only. Alternatively, run git commit --interactive which automatically commits after you’re done. 31'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.sample(pages_and_texts, k =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f53a853-80f4-42e4-b143-51836eda6964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "      <td>228</td>\n",
       "      <td>21</td>\n",
       "      <td>354.75</td>\n",
       "      <td>Git Magic Ben Lynn August 2007 Preface Git is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1795</td>\n",
       "      <td>264</td>\n",
       "      <td>17</td>\n",
       "      <td>448.75</td>\n",
       "      <td>• PDF file: printer-friendly. • EPUB file: E-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2280</td>\n",
       "      <td>400</td>\n",
       "      <td>29</td>\n",
       "      <td>570.00</td>\n",
       "      <td>Introduction I’ll use an analogy to introduce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2681</td>\n",
       "      <td>463</td>\n",
       "      <td>26</td>\n",
       "      <td>670.25</td>\n",
       "      <td>Distributed Control Now imagine a very diﬀicul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1853</td>\n",
       "      <td>318</td>\n",
       "      <td>20</td>\n",
       "      <td>463.25</td>\n",
       "      <td>system, but using systems that scale poorly fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0            0             1419              228                       21   \n",
       "1            1             1795              264                       17   \n",
       "2            2             2280              400                       29   \n",
       "3            3             2681              463                       26   \n",
       "4            4             1853              318                       20   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0            354.75  Git Magic Ben Lynn August 2007 Preface Git is ...  \n",
       "1            448.75  • PDF file: printer-friendly. • EPUB file: E-r...  \n",
       "2            570.00  Introduction I’ll use an analogy to introduce ...  \n",
       "3            670.25  Distributed Control Now imagine a very diﬀicul...  \n",
       "4            463.25  system, but using systems that scale poorly fo...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6db7a068-9ea6-4e96-894c-dacf679d6bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.50</td>\n",
       "      <td>1915.50</td>\n",
       "      <td>325.07</td>\n",
       "      <td>17.98</td>\n",
       "      <td>478.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.85</td>\n",
       "      <td>345.54</td>\n",
       "      <td>61.08</td>\n",
       "      <td>4.74</td>\n",
       "      <td>86.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1084.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>271.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.75</td>\n",
       "      <td>1707.50</td>\n",
       "      <td>285.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>426.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.50</td>\n",
       "      <td>1876.50</td>\n",
       "      <td>320.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>469.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.25</td>\n",
       "      <td>2106.75</td>\n",
       "      <td>365.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>526.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.00</td>\n",
       "      <td>2681.00</td>\n",
       "      <td>463.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>670.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        44.00            44.00            44.00                    44.00   \n",
       "mean         21.50          1915.50           325.07                    17.98   \n",
       "std          12.85           345.54            61.08                     4.74   \n",
       "min           0.00          1084.00           180.00                    10.00   \n",
       "25%          10.75          1707.50           285.00                    14.00   \n",
       "50%          21.50          1876.50           320.50                    18.00   \n",
       "75%          32.25          2106.75           365.00                    22.00   \n",
       "max          43.00          2681.00           463.00                    29.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             44.00  \n",
       "mean             478.88  \n",
       "std               86.38  \n",
       "min              271.00  \n",
       "25%              426.88  \n",
       "50%              469.12  \n",
       "75%              526.69  \n",
       "max              670.25  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4f184db-4d2b-4591-b2f9-2f52d5d9173d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x30c4b5b10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c25779df-9c11-4657-8942-7f96747b29ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 10,\n",
       " 'page_char_count': 1776,\n",
       " 'page_word_count': 293,\n",
       " 'page_sentence_count_raw': 12,\n",
       " 'page_token_count': 444.0,\n",
       " 'text': '$ git push central.server/path/to/proj.git HEAD To check out the source, a developer types: $ git clone central.server/path/to/proj.git After making changes, the developer saves changes locally: $ git commit -a To update to the latest version: $ git pull Any merge conflicts should be resolved then committed: $ git commit -a To check in local changes into the central repository: $ git push If the main server has new changes due to activity by other developers, the push fails, and the developer should pull the latest version, resolve any merge conflicts, then try again. Developers must have SSH access for the above pull and push commands. How- ever, anyone can see the source by typing: $ git clone git://central.server/path/to/proj.git The native git protocol is like HTTP: there is no authentication, so anyone can retrieve the project. Accordingly, by default, pushing is forbidden via the git protocol. Secret Source For a closed-source project, omit the touch command, and ensure you never create a file named git-daemon-export-ok. The repository can no longer be retrieved via the git protocol; only those with SSH access can see it. If all your repos are closed, running the git daemon is unnecessary because all communi- cation occurs via SSH. Bare repositories A bare repository is so named because it has no working directory; it only contains files that are normally hidden away in the .git subdirectory. In other words, it maintains the history of a project, and never holds a snapshot of any given version. A bare repository plays a role similar to that of the main server in a centralized version control system: the home of your project. Developers clone your project from it, and push the latest oﬀicial changes to it. Typically it resides on a server 11'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd9a7eb6-05cd-403e-844c-2b02b8ae1703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1a83ba013c4ef186af085ed6a76125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    item[\"page_senteces_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21835bca-bf81-4368-818e-9312c10673ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 15,\n",
       "  'page_char_count': 1470,\n",
       "  'page_word_count': 272,\n",
       "  'page_sentence_count_raw': 13,\n",
       "  'page_token_count': 367.5,\n",
       "  'text': 'In some directory: $ echo \"I\\'m smarter than my boss\" > myfile.txt $ git init $ git add . $ git commit -m \"Initial commit\" We have created a Git repository that tracks one text file containing a certain message. Now type: $ git checkout -b boss # nothing seems to change after this $ echo \"My boss is smarter than me\" > myfile.txt $ git commit -a -m \"Another commit\" It looks like we’ve just overwritten our file and committed it. But it’s an illusion. Type: $ git checkout master # switch to original version of the file and hey presto! The text file is restored. And if the boss decides to snoop around this directory, type: $ git checkout boss # switch to version suitable for boss\\' eyes You can switch between the two versions of the file as much as you like, and commit to each independently. Dirty Work Say you’re working on some feature, and for some reason, you need to go back three versions and temporarily put in a few print statements to see how some- thing works. Then: $ git commit -a $ git checkout HEAD~3 Now you can add ugly temporary code all over the place. You can even commit these changes. When you’re done, $ git checkout master to return to your original work. Observe that any uncommitted changes are carried over. What if you wanted to save the temporary changes after all? Easy: $ git checkout -b dirty and commit before switching back to the master branch. Whenever you want to return to the dirty changes, simply type: $ git checkout dirty 16',\n",
       "  'sentences': ['In some directory: $ echo \"I\\'m smarter than my boss\" > myfile.txt $ git init $ git add .',\n",
       "   '$ git commit -m \"Initial commit\" We have created a Git repository that tracks one text file containing a certain message.',\n",
       "   'Now type: $ git checkout -b boss # nothing seems to change after this $ echo \"My boss is smarter than me\" > myfile.txt $ git commit -a -m \"Another commit\" It looks like we’ve just overwritten our file and committed it.',\n",
       "   'But it’s an illusion.',\n",
       "   'Type: $ git checkout master # switch to original version of the file and hey presto!',\n",
       "   'The text file is restored.',\n",
       "   \"And if the boss decides to snoop around this directory, type: $ git checkout boss # switch to version suitable for boss' eyes You can switch between the two versions of the file as much as you like, and commit to each independently.\",\n",
       "   'Dirty Work Say you’re working on some feature, and for some reason, you need to go back three versions and temporarily put in a few print statements to see how some- thing works.',\n",
       "   'Then: $ git commit -a $ git checkout HEAD~3 Now you can add ugly temporary code all over the place.',\n",
       "   'You can even commit these changes.',\n",
       "   'When you’re done, $ git checkout master to return to your original work.',\n",
       "   'Observe that any uncommitted changes are carried over.',\n",
       "   'What if you wanted to save the temporary changes after all?',\n",
       "   'Easy: $ git checkout -b dirty and commit before switching back to the master branch.',\n",
       "   'Whenever you want to return to the dirty changes, simply type: $ git checkout dirty 16'],\n",
       "  'page_senteces_count_spacy': 15}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d601b7cf-e9c5-4895-8645-29c73303cdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_senteces_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.50</td>\n",
       "      <td>1915.50</td>\n",
       "      <td>325.07</td>\n",
       "      <td>17.98</td>\n",
       "      <td>478.88</td>\n",
       "      <td>19.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.85</td>\n",
       "      <td>345.54</td>\n",
       "      <td>61.08</td>\n",
       "      <td>4.74</td>\n",
       "      <td>86.38</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1084.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>271.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.75</td>\n",
       "      <td>1707.50</td>\n",
       "      <td>285.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>426.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.50</td>\n",
       "      <td>1876.50</td>\n",
       "      <td>320.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>469.12</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.25</td>\n",
       "      <td>2106.75</td>\n",
       "      <td>365.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>526.69</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.00</td>\n",
       "      <td>2681.00</td>\n",
       "      <td>463.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>670.25</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        44.00            44.00            44.00                    44.00   \n",
       "mean         21.50          1915.50           325.07                    17.98   \n",
       "std          12.85           345.54            61.08                     4.74   \n",
       "min           0.00          1084.00           180.00                    10.00   \n",
       "25%          10.75          1707.50           285.00                    14.00   \n",
       "50%          21.50          1876.50           320.50                    18.00   \n",
       "75%          32.25          2106.75           365.00                    22.00   \n",
       "max          43.00          2681.00           463.00                    29.00   \n",
       "\n",
       "       page_token_count  page_senteces_count_spacy  \n",
       "count             44.00                      44.00  \n",
       "mean             478.88                      19.27  \n",
       "std               86.38                       5.03  \n",
       "min              271.00                      10.00  \n",
       "25%              426.88                      15.00  \n",
       "50%              469.12                      20.00  \n",
       "75%              526.69                      23.00  \n",
       "max              670.25                      29.00  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54d9d70b-b9bd-4292-948c-d3b0776ba621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "def split_list(input_list: list[str],\n",
    "               slice_size: int = num_sentence_chunk_size) ->list[list[str]]:\n",
    "    return [input_list[i:i+slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8616f21b-fdcf-43b2-a8bf-df268ed48139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a14649bf3a4dd6b717577d66540e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62cffb86-29fd-41a0-809c-180ff1c342d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 40,\n",
       "  'page_char_count': 1812,\n",
       "  'page_word_count': 291,\n",
       "  'page_sentence_count_raw': 19,\n",
       "  'page_token_count': 453.0,\n",
       "  'text': 'SHA1 Weaknesses As time passes, cryptographers discover more and more SHA1 weaknesses. Al- ready, finding hash collisions is feasible for well-funded organizations. Within years, perhaps even a typical PC will have enough computing power to silently corrupt a Git repository. Hopefully Git will migrate to a better hash function before further research destroys SHA1. Microsoft Windows Git on Microsoft Windows can be cumbersome: • Cygwin, a Linux-like environment for Windows, contains a Windows port of Git. • Git for Windows is an alternative requiring minimal runtime support, though a few of the commands need some work. Unrelated Files If your project is very large and contains many unrelated files that are constantly being changed, Git may be disadvantaged more than other systems because single files are not tracked. Git tracks changes to the whole project, which is usually beneficial. A solution is to break up your project into pieces, each consisting of related files. Use git submodule if you still want to keep everything in a single repository. Who’s Editing What? Some version control systems force you to explicitly mark a file in some way before editing. While this is especially annoying when this involves talking to a central server, it does have two benefits: 1. Diffs are quick because only the marked files need be examined. 2. One can discover who else is working on the file by asking the central server who has marked it for editing. With appropriate scripting, you can achieve the same with Git. This requires cooperation from the programmer, who should execute particular scripts when editing a file. File History Since Git records project-wide changes, reconstructing the history of a single file requires more work than in version control systems that track individual files. 41',\n",
       "  'sentences': ['SHA1 Weaknesses As time passes, cryptographers discover more and more SHA1 weaknesses.',\n",
       "   'Al- ready, finding hash collisions is feasible for well-funded organizations.',\n",
       "   'Within years, perhaps even a typical PC will have enough computing power to silently corrupt a Git repository.',\n",
       "   'Hopefully Git will migrate to a better hash function before further research destroys SHA1.',\n",
       "   'Microsoft Windows Git on Microsoft Windows can be cumbersome: • Cygwin, a Linux-like environment for Windows, contains a Windows port of Git. •',\n",
       "   'Git for Windows is an alternative requiring minimal runtime support, though a few of the commands need some work.',\n",
       "   'Unrelated Files If your project is very large and contains many unrelated files that are constantly being changed, Git may be disadvantaged more than other systems because single files are not tracked.',\n",
       "   'Git tracks changes to the whole project, which is usually beneficial.',\n",
       "   'A solution is to break up your project into pieces, each consisting of related files.',\n",
       "   'Use git submodule if you still want to keep everything in a single repository.',\n",
       "   'Who’s Editing What?',\n",
       "   'Some version control systems force you to explicitly mark a file in some way before editing.',\n",
       "   'While this is especially annoying when this involves talking to a central server, it does have two benefits: 1.',\n",
       "   'Diffs are quick because only the marked files need be examined.',\n",
       "   '2.',\n",
       "   'One can discover who else is working on the file by asking the central server who has marked it for editing.',\n",
       "   'With appropriate scripting, you can achieve the same with Git.',\n",
       "   'This requires cooperation from the programmer, who should execute particular scripts when editing a file.',\n",
       "   'File History Since Git records project-wide changes, reconstructing the history of a single file requires more work than in version control systems that track individual files.',\n",
       "   '41'],\n",
       "  'page_senteces_count_spacy': 20,\n",
       "  'sentence_chunks': [['SHA1 Weaknesses As time passes, cryptographers discover more and more SHA1 weaknesses.',\n",
       "    'Al- ready, finding hash collisions is feasible for well-funded organizations.',\n",
       "    'Within years, perhaps even a typical PC will have enough computing power to silently corrupt a Git repository.',\n",
       "    'Hopefully Git will migrate to a better hash function before further research destroys SHA1.',\n",
       "    'Microsoft Windows Git on Microsoft Windows can be cumbersome: • Cygwin, a Linux-like environment for Windows, contains a Windows port of Git. •',\n",
       "    'Git for Windows is an alternative requiring minimal runtime support, though a few of the commands need some work.',\n",
       "    'Unrelated Files If your project is very large and contains many unrelated files that are constantly being changed, Git may be disadvantaged more than other systems because single files are not tracked.',\n",
       "    'Git tracks changes to the whole project, which is usually beneficial.',\n",
       "    'A solution is to break up your project into pieces, each consisting of related files.',\n",
       "    'Use git submodule if you still want to keep everything in a single repository.'],\n",
       "   ['Who’s Editing What?',\n",
       "    'Some version control systems force you to explicitly mark a file in some way before editing.',\n",
       "    'While this is especially annoying when this involves talking to a central server, it does have two benefits: 1.',\n",
       "    'Diffs are quick because only the marked files need be examined.',\n",
       "    '2.',\n",
       "    'One can discover who else is working on the file by asking the central server who has marked it for editing.',\n",
       "    'With appropriate scripting, you can achieve the same with Git.',\n",
       "    'This requires cooperation from the programmer, who should execute particular scripts when editing a file.',\n",
       "    'File History Since Git records project-wide changes, reconstructing the history of a single file requires more work than in version control systems that track individual files.',\n",
       "    '41']],\n",
       "  'num_chunks': 2}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d127650-7411-4344-a804-6fb98f34b218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_senteces_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.50</td>\n",
       "      <td>1915.50</td>\n",
       "      <td>325.07</td>\n",
       "      <td>17.98</td>\n",
       "      <td>478.88</td>\n",
       "      <td>19.27</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.85</td>\n",
       "      <td>345.54</td>\n",
       "      <td>61.08</td>\n",
       "      <td>4.74</td>\n",
       "      <td>86.38</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1084.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>271.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.75</td>\n",
       "      <td>1707.50</td>\n",
       "      <td>285.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>426.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.50</td>\n",
       "      <td>1876.50</td>\n",
       "      <td>320.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>469.12</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.25</td>\n",
       "      <td>2106.75</td>\n",
       "      <td>365.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>526.69</td>\n",
       "      <td>23.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.00</td>\n",
       "      <td>2681.00</td>\n",
       "      <td>463.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>670.25</td>\n",
       "      <td>29.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        44.00            44.00            44.00                    44.00   \n",
       "mean         21.50          1915.50           325.07                    17.98   \n",
       "std          12.85           345.54            61.08                     4.74   \n",
       "min           0.00          1084.00           180.00                    10.00   \n",
       "25%          10.75          1707.50           285.00                    14.00   \n",
       "50%          21.50          1876.50           320.50                    18.00   \n",
       "75%          32.25          2106.75           365.00                    22.00   \n",
       "max          43.00          2681.00           463.00                    29.00   \n",
       "\n",
       "       page_token_count  page_senteces_count_spacy  num_chunks  \n",
       "count             44.00                      44.00       44.00  \n",
       "mean             478.88                      19.27        2.39  \n",
       "std               86.38                       5.03        0.54  \n",
       "min              271.00                      10.00        1.00  \n",
       "25%              426.88                      15.00        2.00  \n",
       "50%              469.12                      20.00        2.00  \n",
       "75%              526.69                      23.00        3.00  \n",
       "max              670.25                      29.00        3.00  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37b8592b-7ea5-4617-ab9f-037d92e91b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f2d48a194a46e0b5e70d6d69df5954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts): \n",
    "    for sentence_chunk in item[\"sentence_chunks\"]: \n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "\n",
    "        # Join the sentences together into a paragraph-like structure, aka join the list of sentences into one paragraph\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" => \". A\" (will work for any captial letter)\n",
    "\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get some stats on our chunks\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 chars\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict) \n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ca8fa72-0b38-4e17-adcf-5d4e24fecf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 37,\n",
       "  'sentence_chunk': 'Git is content-addressable: files are not stored according to their filename, but rather by the hash of the data they contain, in a file we call a blob object. We can think of the hash as a unique ID for a file’s contents, so in a sense we are addressing files by their content. The initial blob 6 is merely a header consisting of the object type and its length in bytes; it simplifies internal bookkeeping. Thus I could easily predict what you would see. The file’s name is irrelevant: only the data inside is used to construct the blob object. You may be wondering what happens to identical files. Try adding copies of your file, with any filenames whatsoever. The contents of .git/objects stay the same no matter how many you add. Git only stores the data once. By the way, the files within .git/objects are compressed with zlib so you should not stare at them directly.',\n",
       "  'chunk_char_count': 873,\n",
       "  'chunk_word_count': 158,\n",
       "  'chunk_token_count': 218.25}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6f2c2c3-983a-4c7f-8e3c-7942c67601c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.76</td>\n",
       "      <td>800.92</td>\n",
       "      <td>135.04</td>\n",
       "      <td>200.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.68</td>\n",
       "      <td>364.26</td>\n",
       "      <td>60.72</td>\n",
       "      <td>91.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.00</td>\n",
       "      <td>580.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>145.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.00</td>\n",
       "      <td>886.00</td>\n",
       "      <td>148.00</td>\n",
       "      <td>221.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.00</td>\n",
       "      <td>1028.00</td>\n",
       "      <td>171.00</td>\n",
       "      <td>257.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.00</td>\n",
       "      <td>1658.00</td>\n",
       "      <td>272.00</td>\n",
       "      <td>414.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count       105.00            105.00            105.00             105.00\n",
       "mean         21.76            800.92            135.04             200.23\n",
       "std          12.68            364.26             60.72              91.07\n",
       "min           0.00             41.00              9.00              10.25\n",
       "25%          11.00            580.00            100.00             145.00\n",
       "50%          21.00            886.00            148.00             221.50\n",
       "75%          32.00           1028.00            171.00             257.00\n",
       "max          43.00           1658.00            272.00             414.50"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78be3907-0651-4754-80bf-1413be4b197e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Git Magic Ben Lynn August 2007 Preface Git is ...</td>\n",
       "      <td>950</td>\n",
       "      <td>150</td>\n",
       "      <td>237.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Italian: by Mattia Rigotti. •Korean: by Jung-H...</td>\n",
       "      <td>456</td>\n",
       "      <td>66</td>\n",
       "      <td>114.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>• PDF file: printer-friendly. •EPUB file: E-re...</td>\n",
       "      <td>924</td>\n",
       "      <td>130</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>François Marier maintains the Debian package o...</td>\n",
       "      <td>863</td>\n",
       "      <td>127</td>\n",
       "      <td>215.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Introduction I’ll use an analogy to introduce ...</td>\n",
       "      <td>717</td>\n",
       "      <td>129</td>\n",
       "      <td>179.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            0  Git Magic Ben Lynn August 2007 Preface Git is ...   \n",
       "1            0  Italian: by Mattia Rigotti. •Korean: by Jung-H...   \n",
       "2            1  • PDF file: printer-friendly. •EPUB file: E-re...   \n",
       "3            1  François Marier maintains the Debian package o...   \n",
       "4            2  Introduction I’ll use an analogy to introduce ...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \n",
       "0               950               150             237.50  \n",
       "1               456                66             114.00  \n",
       "2               924               130             231.00  \n",
       "3               863               127             215.75  \n",
       "4               717               129             179.25  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf553ef5-efc1-4fa1-a3f4-be8e8d92983f",
   "metadata": {},
   "source": [
    "### filter chunks of text for short chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f9fe78e-32aa-4af9-8994-575d1a30b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 29.5 | Text: GitHub has an interface that facilitates this: fork the ”gitmagic” project, push your changes, then ask me to merge.44\n",
      "Chunk token count: 29.25 | Text: Developers clone your project from it, and push the latest oﬀicial changes to it. Typically it resides on a server 11\n",
      "Chunk token count: 19.75 | Text: Now you’re in the master branch again, with Part II in the working directory.18\n"
     ]
    }
   ],
   "source": [
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(3).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771fd7c-e197-4fee-b6ae-67afe9504405",
   "metadata": {},
   "source": [
    ">no need to filter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d15dd-fd40-46f6-9f9e-5f00fd138395",
   "metadata": {},
   "source": [
    "### embedding our text chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70adc3c4-1e21-43a4-a797-a009ef9497a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f641c171a408473bbb046777363b1e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cb55b031c049368c8e3a847382dd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5188a8927d394ec69ed8b414e9c2a9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049155534b9340fe9a3d6b61b8786fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febaa0ea22ba470a94faea8089a6495e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383839df94454c7b96b2754b237f6f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e86046c5aea4d3d88283a9ecd7497ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b85f744f4c49ddb086b16c8ad032e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ec4d4004c545608a44be605e73d7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9596916a6a5f49408e2755a2249e5e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8b978060c64f40a50d8d631812305a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path= \"all-mpnet-base-v2\",\n",
    "                                      device = \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1fdceafb-2381-482e-be85-5dca13b3b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0973f90d34bd4dc988fbea685d652d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_chunks):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c002feaa-a156-4f0f-95ce-5394fb1eed57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$ git bisect reset Instead of testing every change by hand, automate the search by running: $ git bisect run my_script Git uses the return value of the given command, typically a one-off script, to decide whether a change is good or bad: the command should exit with code 0 when good, 125 when the change should be skipped, and anything else between 1 and 127 if it is bad. A negative return value aborts the bisect. You can do much more: the help page explains how to visualize bisects, examine or replay the bisect log, and eliminate known innocent changes for a speedier search. Who Made It All Go Wrong?Like many other version control systems, Git has a blame command: $ git blame bug.c which annotates every line in the given file showing who last changed it, and when. Unlike many other version control systems, this operation works offline, reading only from local disk. Personal Experience In a centralized version control system, history modification is a diﬀicult oper- ation, and only available to administrators. Cloning, branching, and merging are impossible without network communication. So are basic operations such as browsing history, or committing a change. In some systems, users require network connectivity just to view their own changes or open a file for editing.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks]\n",
    "text_chunks[57]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8d8e154a-f299-449b-9670-88d1460c5faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9c275317-41a3-4994-9b1f-74847a1efaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0217,  0.0315, -0.0532,  ..., -0.0096,  0.0194, -0.0360],\n",
       "        [ 0.0210,  0.0199, -0.0226,  ...,  0.0085, -0.0036, -0.0356],\n",
       "        [ 0.0474, -0.0186, -0.0213,  ...,  0.0123,  0.0027, -0.0482],\n",
       "        ...,\n",
       "        [ 0.0323, -0.0361, -0.0270,  ..., -0.0407,  0.0150, -0.0252],\n",
       "        [ 0.0504, -0.0207, -0.0460,  ..., -0.0041, -0.0301, -0.0319],\n",
       "        [ 0.0068,  0.0603, -0.0189,  ..., -0.0128,  0.0024, -0.0053]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can experiment to find which batch size leads to best results\n",
    "                                               convert_to_tensor=True)\n",
    "text_chunk_embeddings                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75fef411-9a48-4759-84fa-ae3038edaa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0217,  0.0315, -0.0532,  ..., -0.0096,  0.0194, -0.0360],\n",
       "        [ 0.0210,  0.0199, -0.0226,  ...,  0.0085, -0.0036, -0.0356],\n",
       "        [ 0.0474, -0.0186, -0.0213,  ...,  0.0123,  0.0027, -0.0482],\n",
       "        ...,\n",
       "        [ 0.0323, -0.0361, -0.0270,  ..., -0.0407,  0.0150, -0.0252],\n",
       "        [ 0.0504, -0.0207, -0.0460,  ..., -0.0041, -0.0301, -0.0319],\n",
       "        [ 0.0068,  0.0603, -0.0189,  ..., -0.0128,  0.0024, -0.0053]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunk_embeddings   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12edd06-b302-4974-82da-10294b074a2d",
   "metadata": {},
   "source": [
    "### save embedding to file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bdcdf976-09a1-4587-8f4a-01be8e2485c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4bfb43e9-aff0-45bf-86c9-76436be77f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Git Magic Ben Lynn August 2007 Preface Git is ...</td>\n",
       "      <td>950</td>\n",
       "      <td>150</td>\n",
       "      <td>237.50</td>\n",
       "      <td>[ 2.16734037e-02  3.14504728e-02 -5.31752259e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Italian: by Mattia Rigotti. •Korean: by Jung-H...</td>\n",
       "      <td>456</td>\n",
       "      <td>66</td>\n",
       "      <td>114.00</td>\n",
       "      <td>[ 2.10260246e-02  1.99276339e-02 -2.26166267e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>• PDF file: printer-friendly. •EPUB file: E-re...</td>\n",
       "      <td>924</td>\n",
       "      <td>130</td>\n",
       "      <td>231.00</td>\n",
       "      <td>[ 4.74463515e-02 -1.85674764e-02 -2.13095807e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>François Marier maintains the Debian package o...</td>\n",
       "      <td>863</td>\n",
       "      <td>127</td>\n",
       "      <td>215.75</td>\n",
       "      <td>[ 8.51391669e-05  2.84147169e-02 -2.16863006e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Introduction I’ll use an analogy to introduce ...</td>\n",
       "      <td>717</td>\n",
       "      <td>129</td>\n",
       "      <td>179.25</td>\n",
       "      <td>[-1.14341658e-02 -3.59649956e-02 -1.53461462e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            0  Git Magic Ben Lynn August 2007 Preface Git is ...   \n",
       "1            0  Italian: by Mattia Rigotti. •Korean: by Jung-H...   \n",
       "2            1  • PDF file: printer-friendly. •EPUB file: E-re...   \n",
       "3            1  François Marier maintains the Debian package o...   \n",
       "4            2  Introduction I’ll use an analogy to introduce ...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               950               150             237.50   \n",
       "1               456                66             114.00   \n",
       "2               924               130             231.00   \n",
       "3               863               127             215.75   \n",
       "4               717               129             179.25   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 2.16734037e-02  3.14504728e-02 -5.31752259e-...  \n",
       "1  [ 2.10260246e-02  1.99276339e-02 -2.26166267e-...  \n",
       "2  [ 4.74463515e-02 -1.85674764e-02 -2.13095807e-...  \n",
       "3  [ 8.51391669e-05  2.84147169e-02 -2.16863006e-...  \n",
       "4  [-1.14341658e-02 -3.59649956e-02 -1.53461462e-...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b5b3c-16b4-47c0-ae72-b385e120df2f",
   "metadata": {},
   "source": [
    "### rag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "49b4e7ee-38d3-4475-acc9-8379fe5a1b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Git Magic Ben Lynn August 2007 Preface Git is ...</td>\n",
       "      <td>950</td>\n",
       "      <td>150</td>\n",
       "      <td>237.50</td>\n",
       "      <td>[0.0216734037, 0.0314504728, -0.0531752259, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Italian: by Mattia Rigotti. •Korean: by Jung-H...</td>\n",
       "      <td>456</td>\n",
       "      <td>66</td>\n",
       "      <td>114.00</td>\n",
       "      <td>[0.0210260246, 0.0199276339, -0.0226166267, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>• PDF file: printer-friendly. •EPUB file: E-re...</td>\n",
       "      <td>924</td>\n",
       "      <td>130</td>\n",
       "      <td>231.00</td>\n",
       "      <td>[0.0474463515, -0.0185674764, -0.0213095807, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>François Marier maintains the Debian package o...</td>\n",
       "      <td>863</td>\n",
       "      <td>127</td>\n",
       "      <td>215.75</td>\n",
       "      <td>[8.51391669e-05, 0.0284147169, -0.0216863006, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Introduction I’ll use an analogy to introduce ...</td>\n",
       "      <td>717</td>\n",
       "      <td>129</td>\n",
       "      <td>179.25</td>\n",
       "      <td>[-0.0114341658, -0.0359649956, -0.0153461462, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>42</td>\n",
       "      <td>Global Counter Some centralized version contro...</td>\n",
       "      <td>980</td>\n",
       "      <td>158</td>\n",
       "      <td>245.00</td>\n",
       "      <td>[0.0134130493, 0.0685647056, -0.00317752501, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>42</td>\n",
       "      <td>Unfortunately, with respect to commits, git do...</td>\n",
       "      <td>933</td>\n",
       "      <td>148</td>\n",
       "      <td>233.25</td>\n",
       "      <td>[-0.00950409845, -0.013323958, 0.0379692167, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>42</td>\n",
       "      <td>Interface Quirks For commits A and B, the mean...</td>\n",
       "      <td>197</td>\n",
       "      <td>36</td>\n",
       "      <td>49.25</td>\n",
       "      <td>[0.0323276184, -0.0361246839, -0.0269896649, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>43</td>\n",
       "      <td>Translating This Guide I recommend the followi...</td>\n",
       "      <td>961</td>\n",
       "      <td>157</td>\n",
       "      <td>240.25</td>\n",
       "      <td>[0.0503651574, -0.0206981469, -0.0459663495, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>43</td>\n",
       "      <td>GitHub has an interface that facilitates this:...</td>\n",
       "      <td>118</td>\n",
       "      <td>19</td>\n",
       "      <td>29.50</td>\n",
       "      <td>[0.00682346709, 0.0602663606, -0.0188989583, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number                                     sentence_chunk  \\\n",
       "0              0  Git Magic Ben Lynn August 2007 Preface Git is ...   \n",
       "1              0  Italian: by Mattia Rigotti. •Korean: by Jung-H...   \n",
       "2              1  • PDF file: printer-friendly. •EPUB file: E-re...   \n",
       "3              1  François Marier maintains the Debian package o...   \n",
       "4              2  Introduction I’ll use an analogy to introduce ...   \n",
       "..           ...                                                ...   \n",
       "100           42  Global Counter Some centralized version contro...   \n",
       "101           42  Unfortunately, with respect to commits, git do...   \n",
       "102           42  Interface Quirks For commits A and B, the mean...   \n",
       "103           43  Translating This Guide I recommend the followi...   \n",
       "104           43  GitHub has an interface that facilitates this:...   \n",
       "\n",
       "     chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0                 950               150             237.50   \n",
       "1                 456                66             114.00   \n",
       "2                 924               130             231.00   \n",
       "3                 863               127             215.75   \n",
       "4                 717               129             179.25   \n",
       "..                ...               ...                ...   \n",
       "100               980               158             245.00   \n",
       "101               933               148             233.25   \n",
       "102               197                36              49.25   \n",
       "103               961               157             240.25   \n",
       "104               118                19              29.50   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.0216734037, 0.0314504728, -0.0531752259, -0...  \n",
       "1    [0.0210260246, 0.0199276339, -0.0226166267, -0...  \n",
       "2    [0.0474463515, -0.0185674764, -0.0213095807, 0...  \n",
       "3    [8.51391669e-05, 0.0284147169, -0.0216863006, ...  \n",
       "4    [-0.0114341658, -0.0359649956, -0.0153461462, ...  \n",
       "..                                                 ...  \n",
       "100  [0.0134130493, 0.0685647056, -0.00317752501, -...  \n",
       "101  [-0.00950409845, -0.013323958, 0.0379692167, -...  \n",
       "102  [0.0323276184, -0.0361246839, -0.0269896649, -...  \n",
       "103  [0.0503651574, -0.0206981469, -0.0459663495, 0...  \n",
       "104  [0.00682346709, 0.0602663606, -0.0188989583, -...  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert our embeddings into a torch.tensor\n",
    "embeddings = torch.tensor(np.stack(text_chunks_and_embedding_df[\"embedding\"].tolist(), axis=0), dtype=torch.float32).to(device)\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "text_chunks_and_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "065cef46-3d51-4dfa-8834-cc0f5e23149e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 768])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "42717dea-8306-4d23-afc8-8f65a5c53481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41d31ba3-1b0b-4b0e-b407-7f8942d2db5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 768])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ac139cd1-b205-4f4e-91af-f0bec9e7d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: git structure\n",
      "[INFO] Time taken to get scores on 105 embeddings: 0.00223 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6155, 0.6144, 0.6102, 0.5949, 0.5902]),\n",
       "indices=tensor([94, 88, 44, 87, 79]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define the query\n",
    "query = \"git structure\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query\n",
    "# Note: it's import to embed you query with the same model you embedding your passages\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True).to(\"cpu\")\n",
    "\n",
    "# 3. Get similarity scores with the dot product (use cosine similarity if outputs of model aren't normalized)\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer() \n",
    "\n",
    "print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep top 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4ab9bfd-e57b-4b77-b7ad-0a4e19d4099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([10500, 768])\n",
      "[INFO] Time taken to get scores on 10500 embeddings: 0.00279 seconds.\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
    "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
    "\n",
    "# Perform dot product across 168,000 embeddings\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
    "end_time = timer() \n",
    "\n",
    "print(f\"[INFO] Time taken to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c72e3db-c1f1-4eb0-889e-62aa1a16b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([10500, 768])\n",
      "[INFO] Time taken to get scores on 10500 embeddings: 0.00131 seconds.\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
    "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
    "\n",
    "# Perform dot product across 168,000 embeddings\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
    "end_time = timer() \n",
    "\n",
    "print(f\"[INFO] Time taken to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1b3b01ec-8632-439d-8822-9887f3c1dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ce226af3-1aff-4221-ac4d-1bf97cd8a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'git command to save '\n",
      "\n",
      "Results:\n",
      "Score: 0.6155\n",
      "Text:\n",
      "The current head is kept in the file .git/HEAD, which contains a hash of a\n",
      "commit object. The hash gets updated during a commit as well as many other\n",
      "commands. Branches are almost the same: they are files in .git/refs/heads. Tags\n",
      "too: they live in .git/refs/tags but they are updated by a different set of\n",
      "commands. Git Shortcomings There are some Git issues I’ve swept under the\n",
      "carpet. Some can be handled easily with scripts and hooks, some require\n",
      "reorganizing or redefining the project, and for the few remaining annoyances,\n",
      "one will just have to wait. Or better yet, pitch in and help!40\n",
      "Page number: 39\n",
      "\n",
      "\n",
      "Score: 0.6144\n",
      "Text:\n",
      "Git is content-addressable: files are not stored according to their filename,\n",
      "but rather by the hash of the data they contain, in a file we call a blob\n",
      "object. We can think of the hash as a unique ID for a file’s contents, so in a\n",
      "sense we are addressing files by their content. The initial blob 6 is merely a\n",
      "header consisting of the object type and its length in bytes; it simplifies\n",
      "internal bookkeeping. Thus I could easily predict what you would see. The file’s\n",
      "name is irrelevant: only the data inside is used to construct the blob object.\n",
      "You may be wondering what happens to identical files. Try adding copies of your\n",
      "file, with any filenames whatsoever. The contents of .git/objects stay the same\n",
      "no matter how many you add. Git only stores the data once. By the way, the files\n",
      "within .git/objects are compressed with zlib so you should not stare at them\n",
      "directly.\n",
      "Page number: 37\n",
      "\n",
      "\n",
      "Score: 0.6102\n",
      "Text:\n",
      "Temporary Branches After a while you may realize you are creating short-lived\n",
      "branches frequently for similar reasons: every other branch merely serves to\n",
      "save the current state so you can briefly hop back to an older state to fix a\n",
      "high-priority bug or something. It’s analogous to changing the TV channel\n",
      "temporarily to see what else is on. But instead of pushing a couple of buttons,\n",
      "you have to create, check out, merge, and delete temporary branches. Luckily,\n",
      "Git has a shortcut that is as convenient as a TV remote control: $ git stash\n",
      "This saves the current state in a temporary location (a stash) and restores the\n",
      "previous state. Your working directory appears exactly as it was before you\n",
      "started editing, and you can fix bugs, pull in upstream changes, and so on. When\n",
      "you want to go back to the stashed state, type: $ git stash apply # You may need\n",
      "to resolve some conflicts. You can have multiple stashes, and manipulate them in\n",
      "various ways. See git help stash. As you may have guessed, Git maintains\n",
      "branches behind the scenes to perform this magic trick. Work How You Want You\n",
      "might wonder if branches are worth the bother.\n",
      "Page number: 19\n",
      "\n",
      "\n",
      "Score: 0.5949\n",
      "Text:\n",
      "The object database is elementary yet elegant, and the source of Git’s power.\n",
      "Each file within .git/objects is an object. There are 3 kinds of objects that\n",
      "concern us: blob objects, tree objects, and commit objects. Blobs First, a magic\n",
      "trick. Pick a filename, any filename. In an empty directory: $ echo sweet >\n",
      "YOUR_FILENAME $ git init $ git add .$ find .git/objects -type f You’ll see\n",
      ".git/objects/aa/823728ea7d592acc69b36875a482cdf3fd5c8d. How do I know this\n",
      "without knowing the filename?It’s because the SHA1 hash of: \"blob\" SP \"6\" NUL\n",
      "\"sweet\" LF is aa823728ea7d592acc69b36875a482cdf3fd5c8d, where SP is a space, NUL\n",
      "is a zero byte and LF is a linefeed. You can verify this by typing: $ printf\n",
      "\"blob 6\\000sweet\\n\" | sha1sum 37\n",
      "Page number: 36\n",
      "\n",
      "\n",
      "Score: 0.5902\n",
      "Text:\n",
      "$ git symbolic-ref HEAD shows the current branch name. In practice, you most\n",
      "likely want to remove the ”refs/heads/” and ignore errors: $ git symbolic-ref\n",
      "HEAD 2> /dev/null | cut -b 12- The contrib subdirectory is a treasure trove of\n",
      "tools built on Git. In time, some of them may be promoted to oﬀicial commands.\n",
      "On Debian and Ubuntu, this directory lives at /usr/share/doc/git-core/contrib.\n",
      "One popular resident is workdir/git-new-workdir. Via clever symlinking, this\n",
      "script creates a new working directory whose history is shared with the original\n",
      "repository: $ git-new-workdir an/existing/repo new/directory The new directory\n",
      "and the files within can be thought of as a clone, except since the history is\n",
      "shared, the two trees automatically stay in sync. There’s no need to merge,\n",
      "push, or pull. Daring Stunts These days, Git makes it diﬀicult for the user to\n",
      "accidentally destroy data. But if you know what you are doing, you can override\n",
      "safeguards for common commands. Checkout: Uncommitted changes cause checkout to\n",
      "fail.\n",
      "Page number: 33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"git command to save \"\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indices from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c05e2a57-7fcb-4cee-a2e4-6fe68f5ef2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product between vector1 and vector2: tensor(14.)\n",
      "Dot product between vector1 and vector3: tensor(32.)\n",
      "Dot product between vector1 and vector4: tensor(-14.)\n",
      "Cosine similarity between vector1 and vector2: tensor(1.0000)\n",
      "Cosine similarity between vector1 and vector3: tensor(0.9746)\n",
      "Cosine similarity between vector1 and vector4: tensor(-1.0000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def dot_product(vector1, vector2):\n",
    "    return torch.dot(vector1, vector2)\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = torch.dot(vector1, vector2)\n",
    "\n",
    "    # Get Euclidean/L2 norm\n",
    "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "# Example vectors/tensors\n",
    "vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "vector3 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "vector4 = torch.tensor([-1, -2, -3], dtype=torch.float32)\n",
    "\n",
    "# Calculate dot product\n",
    "print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
    "print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
    "print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
    "\n",
    "# Cosine similarity\n",
    "print(\"Cosine similarity between vector1 and vector2:\", cosine_similarity(vector1, vector2))\n",
    "print(\"Cosine similarity between vector1 and vector3:\", cosine_similarity(vector1, vector3))\n",
    "print(\"Cosine similarity between vector1 and vector4:\", cosine_similarity(vector1, vector4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b0a38d7b-62ce-4939-b217-20b6dd033d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on ({len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores,\n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \"\"\"\n",
    "    Finds relevant passages given a query and prints them out along with their scores.\n",
    "    \"\"\"\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "\n",
    "    # Loop through zipped together scores and indices from torch.topk\n",
    "    for score, idx in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        print(\"Text:\")\n",
    "        print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "        print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b55963b5-cf70-4497-965e-ae8831edb571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on (105 embeddings: 0.00006 seconds.\n",
      "Score: 0.6545\n",
      "Text:\n",
      "Some developers strongly feel history should be immutable, warts and all. Oth-\n",
      "ers feel trees should be made presentable before they are unleashed in public.\n",
      "Git accommodates both viewpoints. Like cloning, branching, and merging, rewrit-\n",
      "ing history is simply another power Git gives you. It is up to you to use it\n",
      "wisely. I Stand Corrected Did you just commit, but wish you had typed a\n",
      "different message?Then run: $ git commit --amend to change the last message.\n",
      "Realized you forgot to add a file?Run git add to add it, and then run the above\n",
      "command. Want to include a few more edits in that last commit?\n",
      "Page number: 20\n",
      "\n",
      "\n",
      "Score: 0.6131\n",
      "Text:\n",
      "Then make those edits and run: $ git commit --amend -a … And Then Some Suppose\n",
      "the previous problem is ten times worse. After a lengthy session you’ve made a\n",
      "bunch of commits. But you’re not quite happy with the way they’re organized, and\n",
      "some of those commit messages could use rewording. Then type: $ git rebase -i\n",
      "HEAD~10 and the last 10 commits will appear in your favourite $EDITOR. A sample\n",
      "excerpt: pick 5c6eb73 Added repo.or.cz link pick a311a64 Reordered analogies in\n",
      "\"Work How You Want\" pick 100834f Added push target to Makefile Older commits\n",
      "precede newer commits in this list, unlike the log command. Here, 5c6eb73 is the\n",
      "oldest commit, and 100834f is the newest. Then: • Remove commits by deleting\n",
      "lines. Like the revert command, but off the record: it will be as if the commit\n",
      "never existed. •Reorder commits by reordering lines. •Replace pick with: – edit\n",
      "to mark a commit for amending. –\n",
      "Page number: 20\n",
      "\n",
      "\n",
      "Score: 0.6104\n",
      "Text:\n",
      "Its contents depend on the commit message as well as the date and time it was\n",
      "created. To match what we have here, we’ll have to tweak it a little: $ git\n",
      "commit --amend -m Shakespeare # Change the commit message.$ git filter-branch\n",
      "--env-filter 'export GIT_AUTHOR_DATE=\"Fri 13 Feb 2009 15:31:30 -0800\"\n",
      "GIT_AUTHOR_NAME=\"Alice\" GIT_AUTHOR_EMAIL=\"alice@example.com\"\n",
      "GIT_COMMITTER_DATE=\"Fri, 13 Feb 2009 15:31:30 -0800\" GIT_COMMITTER_NAME=\"Bob\"\n",
      "GIT_COMMITTER_EMAIL=\"bob@example.com\"' # Rig timestamps and authors.$ find\n",
      ".git/objects -type f You should now see\n",
      ".git/objects/49/993fe130c4b3bf24857a15d7969c396b7bc187 which is the SHA1 hash of\n",
      "its contents: \"commit 158\" NUL \"tree 05b217bb859794d08bb9e4f7f04cbda4b207fbe9\"\n",
      "LF \"author Alice <alice@example.com> 1234567890 -0800\" LF \"committer Bob\n",
      "<bob@example.com> 1234567890 -0800\" LF LF \"Shakespeare\" LF As before, you can\n",
      "run zpipe or cat-file to see for yourself. This is the first commit, so there\n",
      "are no parent commits, but later commits will always contain at least one line\n",
      "identifying a parent commit.39\n",
      "Page number: 38\n",
      "\n",
      "\n",
      "Score: 0.5983\n",
      "Text:\n",
      "In some directory: $ echo \"I'm smarter than my boss\" > myfile.txt $ git init $\n",
      "git add .$ git commit -m \"Initial commit\" We have created a Git repository that\n",
      "tracks one text file containing a certain message. Now type: $ git checkout -b\n",
      "boss # nothing seems to change after this $ echo \"My boss is smarter than me\" >\n",
      "myfile.txt $ git commit -a -m \"Another commit\" It looks like we’ve just\n",
      "overwritten our file and committed it. But it’s an illusion. Type: $ git\n",
      "checkout master # switch to original version of the file and hey presto!The text\n",
      "file is restored. And if the boss decides to snoop around this directory, type:\n",
      "$ git checkout boss # switch to version suitable for boss' eyes You can switch\n",
      "between the two versions of the file as much as you like, and commit to each\n",
      "independently. Dirty Work Say you’re working on some feature, and for some\n",
      "reason, you need to go back three versions and temporarily put in a few print\n",
      "statements to see how some- thing works. Then: $ git commit -a $ git checkout\n",
      "HEAD~3 Now you can add ugly temporary code all over the place. You can even\n",
      "commit these changes.\n",
      "Page number: 15\n",
      "\n",
      "\n",
      "Score: 0.5956\n",
      "Text:\n",
      "Perhaps you’ve just realized you made a monumental mistake and you need to go\n",
      "back to an ancient commit in a long-forgotten branch. By default, Git keeps a\n",
      "commit for at least two weeks, even if you ordered Git to destroy the branch\n",
      "containing it. The trouble is finding the appropriate hash.32\n",
      "Page number: 31\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"git commit change\"\n",
    "# retrieve_relevant_resources(query=query, embeddings=embeddings) \n",
    "print_top_results_and_scores(query=query, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "963af48f-28fc-42e9-98f4-ea6fa286a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System memory: 16.00GB | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\n",
      "use_quantization_config set to: False\n",
      "model_id set to: google/gemma-2b-it\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get total available system memory in GB\n",
    "system_memory_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "\n",
    "# Logic for handling model selection and precision based on available memory\n",
    "if system_memory_gb < 8:\n",
    "    print(f\"Your available system memory is {system_memory_gb:.2f}GB. You may not have enough memory to run Gemma models locally without quantization.\")\n",
    "elif system_memory_gb < 16:\n",
    "    print(f\"System memory: {system_memory_gb:.2f}GB | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif system_memory_gb < 32:\n",
    "    print(f\"System memory: {system_memory_gb:.2f}GB | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "else:\n",
    "    print(f\"System memory: {system_memory_gb:.2f}GB | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "# Output the chosen settings\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "085e3cc8-438d-4246-8876-9883dc2fb5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using attention implementation: sdpa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee7a433cb024d80b3b901215887f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e38714ff059468099afc2c2aa372b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to MPS (Metal Performance Shaders) backend.\n",
      "Model is ready on device: MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_torch_available\n",
    "\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "\n",
    "\n",
    "attn_implementation = \"sdpa\"  # Use regular scaled dot product attention\n",
    "\n",
    "print(f\"Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "\n",
    "model_id = model_id\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_id,\n",
    "    torch_dtype=torch.float16,  # Use float16 for better performance on M1\n",
    "    quantization_config=quantization_config if use_quantization_config else None,\n",
    "    low_cpu_mem_usage=True,  # Important for M1 Pro, manage memory efficiently\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "\n",
    "if not use_quantization_config:\n",
    "    if torch.backends.mps.is_available():\n",
    "        llm_model.to(\"mps\")  # Move model to Metal Performance Shaders (MPS) backend\n",
    "        print(\"Model moved to MPS (Metal Performance Shaders) backend.\")\n",
    "    else:\n",
    "        llm_model.to(\"cpu\")  # Fallback to CPU if MPS is not available\n",
    "        print(\"MPS not available, model moved to CPU.\")\n",
    "else:\n",
    "    llm_model.to(\"cpu\")  # Quantization might require sticking to CPU if MPS isn't supported in quantization workflows\n",
    "\n",
    "print(f\"Model is ready on device: {'MPS' if torch.backends.mps.is_available() else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "be494d0b-fc28-4e0e-ae5b-ccd08162cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "78ed2b17-9e7e-4047-afe9-67661a764587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506172416"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a291214f-9ff2-4aab-b2b5-94bfc55f0728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 5012354048, 'model_mem_mb': 4780.15, 'model_mem_gb': 4.67}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers\n",
    "    model_mem_mb = model_mem_bytes / (1024**2)\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) \n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2), \n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5ab01b6f-0b3a-427c-8295-04a51635383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What is the  significance of git \n",
      "\n",
      "Prompt (formatted):\n",
      "<bos><start_of_turn>user\n",
      "What is the  significance of git<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is the  significance of git \"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False,\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9f2ef8a1-43ee-403f-9ac8-230b037d82fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaTokenizerFast(name_or_path='google/gemma-2b-it', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t5: AddedToken(\"<2mass>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t6: AddedToken(\"[@BOS@]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t7: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t8: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t9: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t10: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t11: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t12: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t13: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t14: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t15: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t16: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t17: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t18: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t19: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t21: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t22: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t23: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t24: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t25: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t26: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t27: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t28: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t29: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t30: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t31: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t33: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t34: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t35: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t36: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t37: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t38: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t39: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t40: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t41: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t42: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t43: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t44: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t45: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t46: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t47: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t48: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t49: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t50: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t51: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t52: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t53: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t54: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t55: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t56: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t57: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t58: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t59: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t60: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t61: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t62: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t63: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t64: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t65: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t66: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t67: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t68: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t69: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t70: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t71: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t72: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t73: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t74: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t75: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t76: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t77: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t78: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t79: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t80: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t81: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t82: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t83: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t84: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t85: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t86: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t87: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t88: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t89: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t90: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t91: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t92: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t93: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t94: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t95: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t96: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t97: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t98: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t99: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t100: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t101: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t102: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t103: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t104: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t105: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t106: AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t107: AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t108: AddedToken(\"\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t109: AddedToken(\"\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t110: AddedToken(\"\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t111: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t112: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t113: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t114: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t115: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t116: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t117: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t118: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t119: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t120: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t121: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t122: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t123: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t124: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t125: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t126: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t127: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t128: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t129: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t130: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t131: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t132: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t133: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t134: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t135: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t136: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t137: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t138: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t139: AddedToken(\"▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t140: AddedToken(\"▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t141: AddedToken(\"▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t142: AddedToken(\"▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t143: AddedToken(\"▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t144: AddedToken(\"▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t145: AddedToken(\"▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t146: AddedToken(\"▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t147: AddedToken(\"▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t148: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t149: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t150: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t152: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t153: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t154: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t155: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t156: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t157: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t158: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t159: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t160: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t161: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t162: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t163: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t164: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t165: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t166: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t167: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t168: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t169: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t170: AddedToken(\"<caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t171: AddedToken(\"<thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t172: AddedToken(\"<tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t173: AddedToken(\"<tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t174: AddedToken(\"<tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t175: AddedToken(\"<th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t176: AddedToken(\"<td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t177: AddedToken(\"</table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t178: AddedToken(\"</caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t179: AddedToken(\"</thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t180: AddedToken(\"</tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t181: AddedToken(\"</tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t182: AddedToken(\"</tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t183: AddedToken(\"</th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t184: AddedToken(\"</td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t185: AddedToken(\"<h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t186: AddedToken(\"<h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t187: AddedToken(\"<h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t188: AddedToken(\"<h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t189: AddedToken(\"<h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t190: AddedToken(\"<h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t191: AddedToken(\"<blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t192: AddedToken(\"</h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t193: AddedToken(\"</h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t194: AddedToken(\"</h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t195: AddedToken(\"</h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t196: AddedToken(\"</h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t197: AddedToken(\"</h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t198: AddedToken(\"</blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t199: AddedToken(\"<strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t200: AddedToken(\"<em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t201: AddedToken(\"<b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t202: AddedToken(\"<i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t203: AddedToken(\"<u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t204: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t205: AddedToken(\"<sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t206: AddedToken(\"<sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t207: AddedToken(\"<code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t208: AddedToken(\"</strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t209: AddedToken(\"</em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t210: AddedToken(\"</b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t211: AddedToken(\"</i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t212: AddedToken(\"</u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t213: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t214: AddedToken(\"</sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t215: AddedToken(\"</sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t216: AddedToken(\"</code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "52d166da-1d21-4925-b02e-8baa80714026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (tokens):\n",
      "tensor([     2,      2,    106,   1645,    108,   1841,    603,    573,    139,\n",
      "          2470,  46407,    576,  25489,    107,    108,    106,   2516,    108,\n",
      "           688,  91168,    576,  28750,  66058,    109,    688,   7198,   7572,\n",
      "          1479,    591, 235330,   6172,   1245,    688,    108, 235287,  28750,\n",
      "           603,    476,  10276,   3797,   2582,   1812,    591, 235330,   6172,\n",
      "        235275,    674,   8563,   6211,    577,   7029,   4559,   1644,    577,\n",
      "           476,   3542,   1163,   1069, 235265,    108, 235287,   1165,   7154,\n",
      "         26337,  11441, 235269,  67127,    577, 235269,    578,  12607,   2167,\n",
      "         16062,    576,    476,   3542, 235265,    108, 235287,  28750,   6572,\n",
      "           476,   3110,   4281,    576,   4559, 235269,   3547,    665,  10154,\n",
      "           604,  26337,    577,   3508,    573,  14764,    576,    476,   3542,\n",
      "        235265,    109,    688, 134318,    578,   6698,  53041,  66058,    108,\n",
      "        235287,  28750,  81504,  18872,   3932,   6733,  26337,    731,  15267,\n",
      "          1174,    577,   1160,    611,    573,   1809,   3542,  27104, 235265,\n",
      "           108, 235287,   1165,  25039,  26337,    577,   7029,   4559,   1644,\n",
      "           731,   3588, 235269,  25308,   1174,   1280,   1024,   1997,  16062,\n",
      "        235269,    578,   4638,    573,   3542,    675,   3588, 235265,    108,\n",
      "        235287,   1417,  46079,  88024,    578,  25361,    573,   5685,    576,\n",
      "         17026,   4559, 235265,    109,    688,   3010,  29107,    578,  10769,\n",
      "        138397,  66058,    108, 235287,  28750,   8563,  26337,    577,   7029,\n",
      "          4559,   1644,    577,   3409,   1163,   1069, 235269,   3547,    665,\n",
      "         10154,    577,  11441,    578,   6530,  30608, 235269,   2279, 138397,\n",
      "          3409, 235269,    578,  10528,  25263,   3409, 235265,    108, 235287,\n",
      "          3339,  19233,   4559, 235269,  28750,    798,   1707,  26337,  11441,\n",
      "         12136,    578,   5004,    575,    573,   3409,   3637, 235269,   8133,\n",
      "           577,  12188,   3409,   3614, 235265,    109,    688,  34410,  49623,\n",
      "           578,  22540,  37211,  66058,    108, 235287,  28750,    798,    614,\n",
      "          1671,    577,   7029,  30608,    578,   5004,   5504,    731,   6211,\n",
      "           689,  10638,    731,  26337, 235265,    108, 235287,  89700,    798,\n",
      "         19441,   5004,    577,   3724,  26337, 235269,   7029,   1024,   7695,\n",
      "        235269,    578,  18482,   1174])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "outputs = llm_model.generate(**input_ids, max_new_tokens=256)\n",
    "\n",
    "\n",
    "outputs_cpu = outputs.to(\"cpu\")\n",
    "\n",
    "print(f\"Model output (tokens):\\n{outputs_cpu[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ce7c29aa-9689-4dc7-bc6a-278dcfcdca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<bos><bos><start_of_turn>user\n",
      "What is the  significance of git<end_of_turn>\n",
      "<start_of_turn>model\n",
      "**Significance of Git:**\n",
      "\n",
      "**Version Control System (VCS):**\n",
      "* Git is a powerful version control system (VCS) that allows users to track changes made to a project over time.\n",
      "* It helps developers identify, revert to, and manage different versions of a project.\n",
      "* Git provides a clear history of changes, making it easier for developers to understand the evolution of a project.\n",
      "\n",
      "**Collaboration and Code Sharing:**\n",
      "* Git facilitates collaboration among multiple developers by allowing them to work on the same project simultaneously.\n",
      "* It enables developers to track changes made by others, merge them into their own versions, and share the project with others.\n",
      "* This promotes teamwork and reduces the risk of losing changes.\n",
      "\n",
      "**Code Maintenance and Refactoring:**\n",
      "* Git allows developers to track changes made to code over time, making it easier to identify and fix bugs, refactoring code, and maintain legacy code.\n",
      "* By tracking changes, Git can help developers identify patterns and issues in the codebase, leading to improved code quality.\n",
      "\n",
      "**Bug Tracking and Issue Resolution:**\n",
      "* Git can be used to track bugs and issues reported by users or identified by developers.\n",
      "* Developers can assign issues to specific developers, track their progress, and resolve them\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1de45d96-455e-4303-a714-c0f8380bfc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is Git and how does it differ from centralized version control systems?',\n",
       " 'Explain the concept of branching in Git and its benefits in project management.',\n",
       " 'What are merge conflicts in Git and how can they be resolved?',\n",
       " 'Describe the process of creating and switching between branches in Git.',\n",
       " 'How does Git handle file renaming and deletions during version control?',\n",
       " 'What is the command to initialize a new Git repository?',\n",
       " 'How can you view the commit history in Git?',\n",
       " \"Explain the purpose of the 'git clone' command.\",\n",
       " 'What is the significance of the HEAD in Git, and how can it be reset?',\n",
       " 'How does Git handle distributed version control compared to centralized systems?']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gpt4_git_questions = [\n",
    "    \"What is Git and how does it differ from centralized version control systems?\",\n",
    "    \"Explain the concept of branching in Git and its benefits in project management.\",\n",
    "    \"What are merge conflicts in Git and how can they be resolved?\",\n",
    "    \"Describe the process of creating and switching between branches in Git.\",\n",
    "    \"How does Git handle file renaming and deletions during version control?\"\n",
    "]\n",
    "\n",
    "\n",
    "manual_git_questions = [\n",
    "    \"What is the command to initialize a new Git repository?\",\n",
    "    \"How can you view the commit history in Git?\",\n",
    "    \"Explain the purpose of the 'git clone' command.\",\n",
    "    \"What is the significance of the HEAD in Git, and how can it be reset?\",\n",
    "    \"How does Git handle distributed version control compared to centralized systems?\"\n",
    "]\n",
    "\n",
    "query_list = gpt4_git_questions + manual_git_questions\n",
    "query_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "86a93334-584b-4d64-a910-faa96efc8e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Git and how does it differ from centralized version control systems?\n",
      "[INFO] Time taken to get scores on (105 embeddings: 0.00154 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.6499, 0.6471, 0.6118, 0.6064, 0.6017], dtype=torch.float32),\n",
       " tensor([58, 83, 22, 86, 29]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\") \n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ae76e439-07a9-4c7f-a3e5-8db1e566383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Describe the process of creating and switching between branches in Git.\n",
      "[INFO] Time taken to get scores on (105 embeddings: 0.00042 seconds.\n",
      "<bos><start_of_turn>user\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What is a Git branch?\n",
      "Answer: A Git branch represents an independent line of development in a project. Branching allows developers to work on features or bug fixes separately from the main codebase, often referred to as the master or main branch. When a branch is created, it contains all the history of the original branch, but changes made in the new branch do not affect the original branch until a merge is performed. This isolation of changes allows for better collaboration and experimentation without disrupting the main project.\n",
      "\n",
      "Example 2:\n",
      "Query: How do you resolve merge conflicts in Git?\n",
      "Answer: Merge conflicts in Git occur when two branches have modifications to the same line in a file or when one branch deletes a file that another branch has modified. Git will pause the merge and mark the conflict in the affected files. To resolve the conflict, a developer needs to manually edit the files by selecting which changes to keep or by combining parts of both conflicting changes. Once resolved, the developer must stage the file and complete the merge by committing the resolved changes.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the purpose of 'git stash'?\n",
      "Answer: The 'git stash' command temporarily saves your modified and staged changes in a stack of unfinished changes, allowing you to switch branches or perform other tasks without committing incomplete work. The saved changes can be reapplied later using 'git stash apply'. This is especially useful when you need to quickly change context and return to a clean working directory without losing your current work.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- Temporary Branches After a while you may realize you are creating short-lived branches frequently for similar reasons: every other branch merely serves to save the current state so you can briefly hop back to an older state to fix a high-priority bug or something. It’s analogous to changing the TV channel temporarily to see what else is on. But instead of pushing a couple of buttons, you have to create, check out, merge, and delete temporary branches. Luckily, Git has a shortcut that is as convenient as a TV remote control: $ git stash This saves the current state in a temporary location (a stash) and restores the previous state. Your working directory appears exactly as it was before you started editing, and you can fix bugs, pull in upstream changes, and so on. When you want to go back to the stashed state, type: $ git stash apply # You may need to resolve some conflicts. You can have multiple stashes, and manipulate them in various ways. See git help stash. As you may have guessed, Git maintains branches behind the scenes to perform this magic trick. Work How You Want You might wonder if branches are worth the bother.\n",
      "- Suppose you have committed Part I and sent it for review. Let’s say you’re in the master branch. Then branch off: $ git checkout -b part2 Next, work on Part II, committing your changes along the way. To err is human, and often you’ll want to go back and fix something in Part I. If you’re lucky, or very good, you can skip these lines.$ git checkout master # Go back to Part I. $ fix_problem $ git commit -a # Commit the fixes.$ git checkout part2 # Go back to Part II.$ git merge master # Merge in those fixes. Eventually, Part I is approved: $ git checkout master # Go back to Part I. $ submit files # Release to the world!$ git merge part2 # Merge in Part II.$ git branch -d part2 # Delete \"part2\" branch.\n",
      "- It’s easy to extend this trick for any number of parts. It’s also easy to branch off retroactively: suppose you belatedly realize you should have created a branch 7 commits ago. Then type: $ git branch -m master part2 # Rename \"master\" branch to \"part2\".$ git branch master HEAD~7 # Create new \"master\", 7 commits upstream. The master branch now contains just Part I, and the part2 branch contains the rest. We are in the latter branch; we created master without switching to it, because we want to continue work on part2. This is unusual. Until now, we’ve been switching to branches immediately after creation, as in: $ git checkout HEAD~7 -b master # Create a branch, and switch to it. Reorganizing a Medley Perhaps you like to work on all aspects of a project in the same branch. You want to keep works-in-progress to yourself and want others to see your commits only when they have been neatly organized.\n",
      "- We touched upon this command in an earlier chapter, when discussing loading old states. At last we can tell the whole story: the files change to the requested state, but we must leave the master branch. Any commits made from now on take your files down a different road, which can be named later. In other words, after checking out an old state, Git automatically puts you in a new, unnamed branch, which can be named and saved with git checkout -b. Quick Fixes You’re in the middle of something when you are told to drop everything and fix a newly discovered bug in commit 1b6d...: $ git commit -a $ git checkout -b fixes 1b6d Then once you’ve fixed the bug: $ git commit -a -m \"Bug fixed\" $ git checkout master and resume work on your original task. You can even merge in the freshly baked bugfix: $ git merge fixes Merging With some version control systems, creating branches is easy but merging them back together is tough. With Git, merging is so trivial that you might be unaware of it happening. We actually encountered merging long ago. The pull command in fact fetches commits and then merges them into your current branch. If you have no local changes, then the merge is a fast forward, a degenerate case akin to fetching the latest version in a centralized version control system.\n",
      "- $ git symbolic-ref HEAD shows the current branch name. In practice, you most likely want to remove the ”refs/heads/” and ignore errors: $ git symbolic-ref HEAD 2> /dev/null | cut -b 12- The contrib subdirectory is a treasure trove of tools built on Git. In time, some of them may be promoted to oﬀicial commands. On Debian and Ubuntu, this directory lives at /usr/share/doc/git-core/contrib. One popular resident is workdir/git-new-workdir. Via clever symlinking, this script creates a new working directory whose history is shared with the original repository: $ git-new-workdir an/existing/repo new/directory The new directory and the files within can be thought of as a clone, except since the history is shared, the two trees automatically stay in sync. There’s no need to merge, push, or pull. Daring Stunts These days, Git makes it diﬀicult for the user to accidentally destroy data. But if you know what you are doing, you can override safeguards for common commands. Checkout: Uncommitted changes cause checkout to fail.\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: Describe the process of creating and switching between branches in Git.\n",
      "Answer:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prompt_formatter(query: str,\n",
    "                     context_items: list[dict]) -> str:\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What is a Git branch?\n",
    "Answer: A Git branch represents an independent line of development in a project. Branching allows developers to work on features or bug fixes separately from the main codebase, often referred to as the master or main branch. When a branch is created, it contains all the history of the original branch, but changes made in the new branch do not affect the original branch until a merge is performed. This isolation of changes allows for better collaboration and experimentation without disrupting the main project.\n",
    "\\nExample 2:\n",
    "Query: How do you resolve merge conflicts in Git?\n",
    "Answer: Merge conflicts in Git occur when two branches have modifications to the same line in a file or when one branch deletes a file that another branch has modified. Git will pause the merge and mark the conflict in the affected files. To resolve the conflict, a developer needs to manually edit the files by selecting which changes to keep or by combining parts of both conflicting changes. Once resolved, the developer must stage the file and complete the merge by committing the resolved changes.\n",
    "\\nExample 3:\n",
    "Query: What is the purpose of 'git stash'?\n",
    "Answer: The 'git stash' command temporarily saves your modified and staged changes in a stack of unfinished changes, allowing you to switch branches or perform other tasks without committing incomplete work. The saved changes can be reapplied later using 'git stash apply'. This is especially useful when you need to quickly change context and return to a clean working directory without losing your current work.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    base_prompt = base_prompt.format(context=context,\n",
    "                                     query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model \n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                           tokenize=False,\n",
    "                                           add_generation_prompt=True)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "query = random.choice(query_list) \n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get relevant resources\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "\n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format our prompt\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f81ad4be-dc77-4a42-9dd4-8bc5e9a4df4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Query: Describe the process of creating and switching between branches in Git.\n",
      "RAG answer:\n",
      "creating and switching between branches in Git:\n",
      "\n",
      "1. **Creating a Branch:** To create a new branch, the `git checkout -b` command is used. This command takes the name of the new branch as its argument. The new branch is created in the current directory, and the working directory is saved to a separate location for the duration of the branch.\n",
      "\n",
      "\n",
      "2. **Switching between Branches:** To switch between branches, the `git checkout` command is used. This command takes the name of the branch to switch to as its argument. The working directory is then changed to the specified branch.\n",
      "\n",
      "\n",
      "3. **Branching Off Retroactively:** In some cases, it may be necessary to branch off a branch that was created at a later time. This can be done using the `git branch -m` command, which creates a new branch that is based on the existing branch. The new branch is named based on the original branch, with the suffix \"-m\" appended to the original branch name.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "outputs = llm_model.generate(\n",
    "    **input_ids,\n",
    "    temperature=0.7,  # Controls creativity of the output\n",
    "    do_sample=True,   # Whether or not to use sampling\n",
    "    max_new_tokens=256  # Limits the number of new tokens generated\n",
    ")\n",
    "\n",
    "\n",
    "outputs_cpu = outputs.to(\"cpu\")\n",
    "\n",
    "output_text = tokenizer.decode(outputs_cpu[0], skip_special_tokens=True)\n",
    "\n",
    "response = output_text[len(prompt):].strip()\n",
    "\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "52dcc7eb-919d-4a56-9f85-efdf17de1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Describe the process of creating and switching between branches in Git.\n",
      "RAG answer:\n",
      "**Creating a Branch**\n",
      "\n",
      "1. **Checkout** the main branch: `git checkout main`\n",
      "2. **Create** a new branch: `git branch <branch_name>`\n",
      "3. **Set** the new branch as the active branch: `git branch --active <branch_name>`\n",
      "\n",
      "**Switching Between Branches**\n",
      "\n",
      "1. **Switch** to the desired branch: `git checkout <branch_name>`\n",
      "2. **Switch** back to the main branch: `git checkout main`\n",
      "\n",
      "**Branching Workflow**\n",
      "\n",
      "1. **Create** a new branch.\n",
      "2. **Switch** to the new branch.\n",
      "3. **Make changes** and commit them.\n",
      "4. **Push** the changes to the remote repository.\n",
      "5. **Create** a pull request to merge the changes into the main branch.\n",
      "6. **Merge** the changes into the main branch.\n",
      "7. **Switch** back to the main branch.\n",
      "8. **Repeat** steps 1-7 for future changes.\n",
      "\n",
      "**Branching Benefits**\n",
      "\n",
      "* **Isolation:** Branches allow you to work on different features without affecting the main codebase.\n",
      "* **Collaboration:** You can create feature branches for team members to work on\n"
     ]
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "input_ids = tokenizer(query, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = llm_model.generate(\n",
    "    **input_ids,\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "outputs_cpu = outputs.to(\"cpu\")\n",
    "output_text = tokenizer.decode(outputs_cpu[0], skip_special_tokens=True)\n",
    "response = output_text[len(query):].strip()\n",
    "\n",
    "print(f\"RAG answer:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef8c7-6a82-4726-8398-36cc2ef1177f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
